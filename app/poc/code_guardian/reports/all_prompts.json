[
    {
        "llm_threat_scan_prompt": "Question: \n            I am an expert penetration tester.\n            Generate a final response in JSON format with the following details:\n            - Programming Language: \"Find the programming language for the given vulnerable source code\"\n            - Compiler Name: \"Tell me the compiler name to compile the patched code received from LLM model\"\n            - Fixed Source Code: \"Get me the fixed source code as a patch by validating against Weakness Enumeration(CWE) and \n                                NATIONAL VULNERABILITY DATABASE(NVD), then fix the code error as well and its supposed to ready to build stage\"\n            - Software Packages:\" List out all the imported libraries or packages used\"\n            - Supporting Operating System: \"List out all the supporting operating system. If its coss platform, respond with 'cross-platform'\"\n            - Executive Summary: \"Describe all the vulnerability in the code snippet and its fix recommentation in details and describe vulnerability discovery and exploitation, and social engineering. If their no vulnerability, respond with 'None'\"\n            - Vulnerability Details: \"Find out all the applicable vulnerabilities and explain one by one from NATIONAL VULNERABILITY DATABASE in the below format\"\n                - \"vulnerability_id\": \"Find out the vulnerability id in the format of CVE-xxx-yyy\",\n                - \"description\": \"Describe the identified vulnerability\",\n                - \"severity\": \"Tell me the severity of this vulnerability\",\n                - \"impact\": \"Explain the vulnerability impact\",\n                - \"recommendation\": \"Explain the vulnerability recommendation to avoid any exploitation\"\n                - \"cvss_score\": \"Provide the CVSS score from Common Vulnerability Scoring System in a numerical format\"\n            - Vulnerability Type: \"List out all the applicable vulnerabilities like XSS, Command Injection, SQL Injection etc\"\n            - Command Weakness Enumeration(CWE): \"List out respective cwe id with details, base findings, attack surface and environment\"\n            - NVD: \"Provide standard meta data from NATIONAL VULNERABILITY DATABASE\"\n            - Literature Survey: \"List out all the related literature survey reference papers with URL\"\n            - Static Code Analysis: \"Access any related static code analysis tool and find out the code errors like syntax and semantics deeply if possible\"\n            - coding standard violations: \"Recommended coding standard violations if available otherwise say 'None'\"\n            - Test Cases: \"Create a testcases applicable for the given code snippet to mitigate vulnerability\"\n            - Conclusion: \"The assessment has identified critical vulnerabilities that require immediate attention to prevent potential security breaches and data loss.\"\n            Given Vulnerable source code snippet is `\nfrom flask import Flask, render_template, request\napp = Flask(__name__)\n@app.route('/user_profile')\ndef user_profile():\n    # Simulate user-generated content\n    user_input = request.args.get('user_input', '')\n    \n    return user_input\n\nif __name__ == '__main__':\n    app.run(debug=False)\n`\n\n            Reply the answer in JSON form with associated properties are programming_language, compiler_name, fixed_source_code, software_packages,\n            supporting_operating_system, executive_summary, vulnerability_details, vulnerability_type, cwe, cvss_score, nvd, literature_survey, \n            static_code_analysis, conclusion\n            \n\n        Answer: Return the modified fixed programming code without any format change or any additional details.",
        "llm_code_comparision_prompt": "Question: \n            I have an original source code snippet that contains a known vulnerability, and a patched version of that snippet which is \n            intended to fix the vulnerability. Please analyze both versions and determine whether the patch correctly addresses the \n            vulnerability without introducing any new issues.\n\n            Here is the original source code with the vulnerability:\n            `\nfrom flask import Flask, render_template, request\napp = Flask(__name__)\n@app.route('/user_profile')\ndef user_profile():\n    # Simulate user-generated content\n    user_input = request.args.get('user_input', '')\n    \n    return user_input\n\nif __name__ == '__main__':\n    app.run(debug=False)\n`\n\n            Here is the patched source code:\n            `from flask import Flask, render_template, request\n\napp = Flask(__name__)\n\n@app.route('/user_profile')\ndef user_profile():\n    user_input = request.args.get('user_input', '')\n    # Perform input validation to prevent code injection\n    user_input = user_input.replace('<', '&lt;').replace('>', '&gt;')\n    return user_input\n\nif __name__ == '__main__':\n    app.run(debug=False)`\n\n            Please assess the following:\n            1. Does the patched code resolve the original vulnerability?\n            2. Are there any new potential security issues introduced by the patch?\n            3. Does the patched code maintain the original functionality and performance?\n            4. Are there any best practices or coding standards that the patch does not adhere to?\n\n            Provide a detailed analysis of the effectiveness of the patch in JSON form.\n\n            \n\n        Answer: Return the comparision results.",
        "llm_dev_patch_comp_prompt": "Question: \n            I have two patches for a piece of source code that are intended to fix a specific security vulnerability. \n            One patch is from developers committed in github and another patch is from gpt response. \n            Please analyze both patches and determine which one more effectively mitigates the vulnerability, considering \n            the potential for introducing new vulnerabilities and overall security best practices.\n\n            Here is the description of the original vulnerability:\n            `The code snippet is vulnerable to a potential code injection attack. It takes user input from the 'user_input' query parameter without performing any input validation. An attacker can exploit this vulnerability by injecting malicious code or scripts through the query parameter, leading to various security risks such as cross-site scripting (XSS) attacks. To fix this vulnerability, the code has been modified to include input validation, where any '<' or '>' characters are replaced with their respective HTML entities ('&lt;' and '&gt;'). This helps prevent code injection attacks and ensures the safety of user-generated content.`\n\n            Here is the first patch from developer code:\n            `\nfrom flask import Flask, render_template, request, escape\napp = Flask(__name__)\n@app.route('/user_profile')\ndef user_profile():\n    # Simulate user-generated content\n    user_input = request.args.get('user_input', '')\n    if user_input:\n        user_input = escape(user_input)\n    \n    return user_input\n\nif __name__ == '__main__':\n    app.run(debug=False)\n`\n\n            And here is the second patch from gpt4 response:\n            `from flask import Flask, render_template, request\n\napp = Flask(__name__)\n\n@app.route('/user_profile')\ndef user_profile():\n    user_input = request.args.get('user_input', '')\n    # Perform input validation to prevent code injection\n    user_input = user_input.replace('<', '&lt;').replace('>', '&gt;')\n    return user_input\n\nif __name__ == '__main__':\n    app.run(debug=False)`\n\n            Please compare the two patches and provide an analysis of which is the better solution for the vulnerability in question, and explain why.\n\n            \n\n        Answer: Return the modified fixed programming code without any format change or any additional details."
    }
]